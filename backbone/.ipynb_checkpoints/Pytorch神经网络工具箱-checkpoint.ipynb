{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于nn.Module类构建网络层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:00:41.583664Z",
     "start_time": "2020-05-19T12:00:35.512470Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:15:45.307344Z",
     "start_time": "2020-01-17T13:15:37.880174Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "基于nn.Module类构建全连接层\n",
    "'''\n",
    "# 构建基础网络结构，首先继承nn.Module类\n",
    "class Linear(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(Linear, self).__init__() # 调用Linear的父类构造初始化函数\n",
    "        # 使用 nn.Parameter 构造学习参数 特殊的tensor构造方法，默认需要求导\n",
    "        self.w = nn.Parameter(torch.randn(in_dim, out_dim))\n",
    "        self.b = nn.Parameter(torch.randn(out_dim))\n",
    "    \n",
    "    '''\n",
    "    构造forward函数实现前向计算\n",
    "    '''\n",
    "    def forward(self, x):\n",
    "        x = x.matmul(self.w)\n",
    "        y = x + self.b.expand_as(x)  # 保证x与b的形状相同\n",
    "        return y\n",
    "\n",
    "class Perception(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, out_dim):\n",
    "        super(Perception, self).__init__()\n",
    "        self.layer1 = Linear(in_dim, hid_dim)\n",
    "        self.layer2 = Linear(hid_dim, out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        y = torch.sigmoid(x)\n",
    "        y = self.layer2(y)\n",
    "        y = torch.sigmoid(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:20:48.647402Z",
     "start_time": "2020-01-17T13:20:48.546639Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "初始化Perception\n",
    "'''\n",
    "\n",
    "perception=Perception(2,3,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:21:28.697296Z",
     "start_time": "2020-01-17T13:21:28.686317Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perception(\n",
       "  (layer1): Linear()\n",
       "  (layer2): Linear()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "查看Perception内容\n",
    "'''\n",
    "\n",
    "perception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:24:50.868888Z",
     "start_time": "2020-01-17T13:24:50.479929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer1.w Parameter containing:\n",
      "tensor([[-0.7899,  1.4949, -0.8194],\n",
      "        [ 1.8381,  0.3162,  0.3809]], requires_grad=True)\n",
      "layer1.b Parameter containing:\n",
      "tensor([-0.6838, -0.8690, -0.4233], requires_grad=True)\n",
      "layer2.w Parameter containing:\n",
      "tensor([[-0.6709,  0.8310],\n",
      "        [ 1.9588,  1.5598],\n",
      "        [ 0.0765, -0.3974]], requires_grad=True)\n",
      "layer2.b Parameter containing:\n",
      "tensor([-1.5968,  1.0403], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "使用named_parameters()返回学习参数\n",
    "'''\n",
    "\n",
    "for name, parameter in perception.named_parameters():\n",
    "    print(name, parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:29:15.386695Z",
     "start_time": "2020-01-17T13:29:15.293946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1834, 0.7787],\n",
      "        [0.2718, 0.8262],\n",
      "        [0.1400, 0.8380],\n",
      "        [0.1669, 0.7786]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "制作样本x，输出\n",
    "'''\n",
    "\n",
    "x = torch.randn(4, 2)  # 4个样本，特征维2维\n",
    "y = perception(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用nn.sequential模块构建神经网络模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:42:52.248813Z",
     "start_time": "2020-01-17T13:42:52.244822Z"
    }
   },
   "outputs": [],
   "source": [
    "class Perception(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, out_dim):\n",
    "        super(Perception, self).__init__()\n",
    "        self.layer = nn.Sequential(nn.Linear(in_dim, hid_dim), nn.Sigmoid(),\n",
    "                                   nn.Linear(hid_dim, out_dim), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.layer(x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:54:35.515666Z",
     "start_time": "2020-01-17T13:54:34.113418Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Perception(10, 100, 2).cuda()  # 在GPU端创建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:54:35.570527Z",
     "start_time": "2020-01-17T13:54:35.565534Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perception(\n",
       "  (layer): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=100, bias=True)\n",
       "    (1): Sigmoid()\n",
       "    (2): Linear(in_features=100, out_features=2, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T13:54:38.855737Z",
     "start_time": "2020-01-17T13:54:38.848756Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 10).cuda()\n",
    "y = model(x)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数的使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T14:03:02.779473Z",
     "start_time": "2020-01-17T14:03:02.772465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4575, 0.4903],\n",
      "        [0.4512, 0.4768]], grad_fn=<SigmoidBackward>)\n",
      "tensor(0.6950, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "net = Perception(10, 100, 2)\n",
    "x = torch.randn(2, 10)\n",
    "y = net(x)\n",
    "print(y)\n",
    "label = torch.Tensor([0, 1]).long()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(y, label)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化器的使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T15:02:12.732041Z",
     "start_time": "2020-01-17T15:02:12.728036Z"
    }
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim1, hid_dim2, out_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer = nn.Sequential(nn.Linear(in_dim, hid_dim1), nn.ReLU(),\n",
    "                                   nn.Linear(hid_dim1, hid_dim2), nn.ReLU(),\n",
    "                                   nn.Linear(hid_dim2, out_dim), nn.ReLU())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T15:02:14.766814Z",
     "start_time": "2020-01-17T15:02:13.695647Z"
    }
   },
   "outputs": [],
   "source": [
    "model=MLP(28*28,300,200,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T15:02:20.222196Z",
     "start_time": "2020-01-17T15:02:20.212224Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (layer): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=300, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=300, out_features=200, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=200, out_features=10, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T15:03:39.931905Z",
     "start_time": "2020-01-17T15:03:39.927917Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "设置优化器\n",
    "'''\n",
    "\n",
    "optimizer = optim.SGD(params=model.parameters(), lr=0.01)  # 优化参数设置 params=model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T15:05:35.043437Z",
     "start_time": "2020-01-17T15:05:34.289980Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 1.9691e-01, 0.0000e+00, 0.0000e+00, 4.8709e-02, 1.3447e-01,\n",
       "         2.6145e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 1.4459e-01, 1.4253e-02, 5.5156e-02, 7.3206e-02, 1.3473e-01,\n",
       "         0.0000e+00, 6.0356e-03, 0.0000e+00, 3.0023e-02],\n",
       "        [0.0000e+00, 1.4578e-01, 9.8806e-02, 0.0000e+00, 1.0154e-01, 4.6041e-02,\n",
       "         5.3070e-02, 6.5560e-02, 3.6377e-03, 8.5641e-03],\n",
       "        [0.0000e+00, 4.2270e-03, 3.7228e-02, 9.7767e-02, 0.0000e+00, 0.0000e+00,\n",
       "         1.2646e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 1.4399e-01, 0.0000e+00, 0.0000e+00, 6.0356e-02, 9.7392e-02,\n",
       "         3.6003e-03, 9.6851e-03, 0.0000e+00, 1.9400e-01],\n",
       "        [0.0000e+00, 1.1987e-01, 1.0303e-01, 3.4398e-02, 1.0117e-01, 1.1314e-01,\n",
       "         1.0674e-02, 1.1305e-01, 0.0000e+00, 6.3934e-02],\n",
       "        [0.0000e+00, 1.2154e-01, 0.0000e+00, 2.2547e-02, 4.5701e-02, 1.5551e-01,\n",
       "         3.3791e-02, 2.8160e-02, 7.1867e-03, 4.6830e-02],\n",
       "        [0.0000e+00, 4.9197e-02, 0.0000e+00, 7.4534e-02, 6.9757e-03, 1.0678e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 1.7895e-02],\n",
       "        [0.0000e+00, 1.7362e-01, 0.0000e+00, 1.4398e-02, 0.0000e+00, 1.9201e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6832e-03],\n",
       "        [0.0000e+00, 9.5639e-02, 8.6822e-05, 0.0000e+00, 4.8473e-02, 5.0646e-02,\n",
       "         0.0000e+00, 9.8752e-02, 0.0000e+00, 8.7132e-02]],\n",
       "       grad_fn=<ThresholdBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "输入输出计算\n",
    "'''\n",
    "\n",
    "x = torch.randn(10, 28 * 28)\n",
    "y = model(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T15:05:30.087716Z",
     "start_time": "2020-01-17T15:05:29.825239Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 4, 7, 9, 3, 4, 5, 3, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "计算损失\n",
    "'''\n",
    "\n",
    "label = torch.Tensor([1, 0, 4, 7, 9, 3, 4, 5, 3, 2]).long()\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T15:06:40.918533Z",
     "start_time": "2020-01-17T15:06:40.249131Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2765, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "loss = criterion(y, label)\n",
    "loss  # 10个样本的所有损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T15:08:44.677358Z",
     "start_time": "2020-01-17T15:08:42.387481Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "每次更新梯度前都要清空梯度\n",
    "'''\n",
    "\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用torch.model模块载入已有模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T15:18:44.248448Z",
     "start_time": "2020-03-11T15:18:41.669193Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T15:18:51.133743Z",
     "start_time": "2020-03-11T15:18:48.596274Z"
    }
   },
   "outputs": [],
   "source": [
    "vgg = models.vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T15:18:51.151608Z",
     "start_time": "2020-03-11T15:18:51.135649Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace)\n",
       "    (2): Dropout(p=0.5)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace)\n",
       "    (5): Dropout(p=0.5)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "查看模型所有参数\n",
    "'''\n",
    "\n",
    "vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-17T15:44:04.600474Z",
     "start_time": "2020-01-17T15:44:04.595488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "查看模型属性：models中的模型都分为特征层和分类层\n",
    "'''\n",
    "\n",
    "len(vgg.features), len(vgg.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T15:19:04.904248Z",
     "start_time": "2020-03-11T15:19:04.898265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReLU(inplace)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "索引\n",
    "'''\n",
    "\n",
    "vgg.classifier[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-11T15:19:27.936863Z",
     "start_time": "2020-03-11T15:19:27.931850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (25): ReLU(inplace)\n",
       "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (27): ReLU(inplace)\n",
       "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (29): ReLU(inplace)\n",
       "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "切片\n",
    "'''\n",
    "\n",
    "vgg.features[23:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载预训练模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    vgg1=models.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T15:42:31.899722Z",
     "start_time": "2020-03-12T15:42:31.895742Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 继承Dataset类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T16:44:52.006721Z",
     "start_time": "2020-03-12T16:44:52.001734Z"
    }
   },
   "outputs": [],
   "source": [
    "class my_data(Dataset):\n",
    "    def __init__(self,image_path,annotation_path,transform=None):\n",
    "        # 初始化读取数据集\n",
    "        pass\n",
    "    def __len__(self):\n",
    "        # 获取数据集大小\n",
    "        pass\n",
    "    def __getitem__(self,idx):\n",
    "        # 对于指定的idx，读取数据并索引\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 数据变换与增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T16:44:53.401656Z",
     "start_time": "2020-03-12T16:44:53.396642Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = my_data(\"image_path\",\n",
    "                  'annotation_path',\n",
    "                  transform=transforms.Compose([\n",
    "                      transforms.Resize(256),\n",
    "                      transforms.RandomHorizontalFlip(),\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "                  ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 继承dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=1)\n",
    "\n",
    "data_iter = iter(dataloader)\n",
    "for step in range(iters_per_epoch):\n",
    "    data = next(data_iter)\n",
    "    # 将data用于训练网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visdom可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-21T08:51:20.850698Z",
     "start_time": "2020-01-21T08:51:20.530979Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'random_image'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WinError 10054] 远程主机强迫关闭了一个现有的连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n",
      "[WinError 10061] 由于目标计算机积极拒绝，无法连接。\n"
     ]
    }
   ],
   "source": [
    "vis = visdom.Visdom(env='first')\n",
    "vis.text('first visdom', win='text1')\n",
    "vis.text('hello PyTorch', win='text1', append=True)\n",
    "\n",
    "for i in range(20):\n",
    "    vis.line(X=torch.FloatTensor([i]),\n",
    "             Y=torch.FloatTensor([-i**2 + 20 * i + 1]),\n",
    "             opts={'title': 'y=-x^2+20x+1'},\n",
    "             win='loss',\n",
    "             update='append')\n",
    "\n",
    "vis.image(torch.randn(3, 256, 256), win='random_image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T14:05:07.845142Z",
     "start_time": "2020-03-13T14:05:07.839153Z"
    }
   },
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(in_channels=1,\n",
    "                 out_channels=1,\n",
    "                 kernel_size=3,\n",
    "                 stride=1,\n",
    "                 padding=1,\n",
    "                 dilation=1,\n",
    "                 groups=1,\n",
    "                 bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T14:05:29.367366Z",
     "start_time": "2020-03-13T14:05:29.358390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T14:06:25.963577Z",
     "start_time": "2020-03-13T14:06:25.495236Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-0.1673,  0.2720,  0.1343],\n",
       "          [ 0.2503,  0.0463, -0.3319],\n",
       "          [-0.2572,  0.2446,  0.1711]]]], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "查看卷积权重与偏置\n",
    "'''\n",
    "\n",
    "conv.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T14:06:31.561757Z",
     "start_time": "2020-03-13T14:06:31.554774Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.2411], requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T14:08:36.059800Z",
     "start_time": "2020-03-13T14:08:35.840388Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 5, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(1, 1, 5, 5)\n",
    "y = conv(x)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 激活函数层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T14:13:24.472789Z",
     "start_time": "2020-03-13T14:13:24.461817Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.7311, 0.7311, 0.7311, 0.7311],\n",
       "          [0.7311, 0.7311, 0.7311, 0.7311],\n",
       "          [0.7311, 0.7311, 0.7311, 0.7311],\n",
       "          [0.7311, 0.7311, 0.7311, 0.7311]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Sigmoid函数\n",
    "'''\n",
    "x = torch.ones(1, 1, 4, 4)\n",
    "sigmoid = nn.Sigmoid()\n",
    "y = sigmoid(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T14:16:16.058372Z",
     "start_time": "2020-03-13T14:16:16.046404Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.6931, 0.3609],\n",
       "          [0.3801, 0.0000]]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "ReLU函数\n",
    "'''\n",
    "\n",
    "x = torch.randn(1, 1, 2, 2)\n",
    "relu = nn.ReLU(True)\n",
    "y = relu(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T14:19:08.905467Z",
     "start_time": "2020-03-13T14:19:08.796607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0087, -0.0091],\n",
       "          [-0.0550, -0.0588]]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "LeakyRelu函数\n",
    "'''\n",
    "\n",
    "x = torch.randn(1, 1, 2, 2)\n",
    "leakyrelu = nn.LeakyReLU(0.04, True)\n",
    "y = leakyrelu(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T14:21:40.275450Z",
     "start_time": "2020-03-13T14:21:40.268469Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1665, 0.5265, 0.2536, 0.0534]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Softmax函数\n",
    "'''\n",
    "import torch.nn.functional as F\n",
    "\n",
    "score = torch.randn(1, 4)\n",
    "prob = F.softmax(score, 1)\n",
    "prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 池化层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T14:26:42.931002Z",
     "start_time": "2020-03-13T14:26:42.918011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.4670, 1.3440],\n",
       "          [0.1555, 1.8045]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "最大池化层\n",
    "'''\n",
    "\n",
    "x = torch.randn(1, 1, 4, 4)\n",
    "Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "y = Maxpool(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T14:29:53.223755Z",
     "start_time": "2020-03-13T14:29:53.111731Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[3.0000, 4.5000],\n",
       "          [5.2500, 6.7500]]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "平均池化层\n",
    "'''\n",
    "\n",
    "x = torch.randint(16, (1, 1, 4, 4)).float()\n",
    "Avgpool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "y = Avgpool(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T14:57:44.316029Z",
     "start_time": "2020-03-13T14:57:44.309016Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[8.8125]]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "全局平均池化\n",
    "'''\n",
    "\n",
    "x=torch.randint(16,(1,1,4,4)).float()\n",
    "GAP=nn.AdaptiveAvgPool2d((1,1)) # 表示输出为1*1\n",
    "y=GAP(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T14:35:59.454680Z",
     "start_time": "2020-03-13T14:35:59.269682Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[3., 2., 1., 0.],\n",
      "          [2., 1., 7., 2.],\n",
      "          [1., 6., 1., 1.],\n",
      "          [6., 6., 1., 2.]],\n",
      "\n",
      "         [[6., 0., 0., 5.],\n",
      "          [4., 6., 1., 6.],\n",
      "          [6., 5., 5., 1.],\n",
      "          [7., 2., 2., 1.]]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 6.,  4.,  0.,  0.],\n",
       "          [ 4.,  0., 14.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.],\n",
       "          [ 0., 12.,  0.,  4.]],\n",
       "\n",
       "         [[12.,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0.,  0.],\n",
       "          [12.,  0., 10.,  0.],\n",
       "          [14.,  4.,  0.,  0.]]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Dropout层\n",
    "'''\n",
    "\n",
    "x = torch.randint(8, (1, 2, 4, 4)).float()\n",
    "drop = nn.Dropout(0.5, inplace=False)\n",
    "print(x)\n",
    "y = drop(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BN层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T14:42:09.556253Z",
     "start_time": "2020-03-13T14:42:09.520357Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.8812, -0.2533,  0.1360, -0.6615],\n",
       "          [ 0.1609,  0.1578,  0.7782, -0.8290],\n",
       "          [ 0.3836, -0.5014,  0.3428, -0.0848],\n",
       "          [-0.3416,  0.5786,  0.1835, -0.9308]],\n",
       "\n",
       "         [[ 0.2202, -0.3556, -0.4825, -1.2569],\n",
       "          [-1.8200,  0.7470,  0.6060, -0.3318],\n",
       "          [ 0.0833,  0.4898,  1.7687,  0.1241],\n",
       "          [ 0.4721, -0.3169, -0.0417,  0.0943]],\n",
       "\n",
       "         [[-0.4088,  0.5112,  1.4011, -1.0813],\n",
       "          [-0.1116, -1.3820, -0.9311,  0.5352],\n",
       "          [ 1.0949, -0.5286, -1.6304,  0.3013],\n",
       "          [ 1.1429,  0.0675,  0.6494,  0.3702]]]],\n",
       "       grad_fn=<NativeBatchNormBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 4, 4)\n",
    "bn = nn.BatchNorm2d(3)\n",
    "y = bn(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T14:59:27.407970Z",
     "start_time": "2020-03-13T14:59:27.301271Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.2855,  1.2604, -0.0861, -0.1371],\n",
       "          [ 0.8705, -1.2627,  0.9981,  1.7073],\n",
       "          [ 0.8338, -2.5596, -0.4494,  0.5797],\n",
       "          [-0.6013, -0.5895, -1.1241,  1.2017]],\n",
       "\n",
       "         [[ 0.5287, -0.1574, -0.1680, -0.5650],\n",
       "          [-0.2542,  0.2076,  1.2809, -0.1279],\n",
       "          [ 0.4048,  0.2107, -1.7436,  0.9369],\n",
       "          [ 1.6253, -0.9658, -1.5342, -0.6062]],\n",
       "\n",
       "         [[ 0.7557, -0.0117,  0.9498,  0.4648],\n",
       "          [ 0.4619, -1.3276,  1.8288, -0.7186],\n",
       "          [ 2.1309, -0.5831,  0.9492,  0.9241],\n",
       "          [-0.0964, -0.3702,  0.0217, -0.7597]],\n",
       "\n",
       "         [[-0.7778, -1.3908, -1.4115, -1.3458],\n",
       "          [-2.0215, -0.5317,  0.4191,  0.4915],\n",
       "          [-0.6804,  0.1562, -0.3185,  0.1391],\n",
       "          [ 0.5365, -0.8223,  1.6876,  1.2507]]],\n",
       "\n",
       "\n",
       "        [[[-0.1483,  0.1011,  0.3852, -0.9708],\n",
       "          [-0.9699, -0.3725,  0.4625, -1.5210],\n",
       "          [ 0.3666, -0.3853,  2.3750, -0.2385],\n",
       "          [-0.0188,  0.4155, -0.3188, -1.0193]],\n",
       "\n",
       "         [[ 0.8678, -0.4090,  0.1687, -0.1696],\n",
       "          [-0.0968, -0.2936,  0.8056, -2.1477],\n",
       "          [ 0.3635, -1.0765, -0.8558, -1.1331],\n",
       "          [ 2.0476,  0.3235,  1.8762,  1.5863]],\n",
       "\n",
       "         [[-0.3714,  0.8177, -1.1561,  0.6380],\n",
       "          [-0.5823, -1.6955, -1.8005, -1.3271],\n",
       "          [-0.8124, -0.5979,  0.6915,  0.9944],\n",
       "          [ 1.7344, -1.2921, -0.0892,  0.1883]],\n",
       "\n",
       "         [[ 1.3114,  0.6250,  0.7865, -0.4858],\n",
       "          [ 0.6988,  0.4108,  0.3503,  0.7960],\n",
       "          [ 1.0157, -0.6682,  1.6637, -0.0389],\n",
       "          [ 0.6586, -0.9260, -1.9788,  0.4410]]]], grad_fn=<AddcmulBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "GN层\n",
    "'''\n",
    "\n",
    "x = torch.randn(2, 4, 4, 4)\n",
    "GN = nn.GroupNorm(2, 4)\n",
    "y = GN(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-13T14:50:25.854018Z",
     "start_time": "2020-03-13T14:50:25.452110Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5103, -0.6042,  1.0969,  ...,  0.2295, -0.6232,  1.2950],\n",
       "        [-0.2470, -0.2080,  1.2347,  ..., -0.6928, -0.8202, -0.2554],\n",
       "        [-0.7302, -0.6208, -1.1124,  ..., -0.5216,  0.0690,  0.0302],\n",
       "        [ 0.3536, -0.5108, -0.0231,  ...,  0.2732,  0.1249,  0.3771]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4, 1024)\n",
    "liner = nn.Linear(1024, 4096)\n",
    "y = liner(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 空洞卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:37:22.880702Z",
     "start_time": "2020-05-19T12:37:22.872752Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[3., 1., 1., 0., 1.],\n",
       "          [1., 2., 0., 2., 2.],\n",
       "          [2., 3., 1., 0., 1.],\n",
       "          [1., 1., 0., 0., 2.],\n",
       "          [2., 2., 3., 1., 3.]]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(4, size=(1, 1, 5, 5)).float()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:37:29.828984Z",
     "start_time": "2020-05-19T12:37:29.824964Z"
    }
   },
   "outputs": [],
   "source": [
    "kernel = torch.tensor([[[[1., 1., 1.], [1., 1., 1.], [1., 1., 1.]]]],requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:37:30.240321Z",
     "start_time": "2020-05-19T12:37:30.231336Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.]]]], requires_grad=True)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:37:30.693103Z",
     "start_time": "2020-05-19T12:37:30.688146Z"
    }
   },
   "outputs": [],
   "source": [
    "conv_dilation = nn.Conv2d(in_channels=1,\n",
    "                          out_channels=1,\n",
    "                          kernel_size=3,\n",
    "                          stride=1,\n",
    "                          padding=0,\n",
    "                          dilation=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:37:31.171031Z",
     "start_time": "2020-05-19T12:37:31.162053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[1., 1., 1.],\n",
       "          [1., 1., 1.],\n",
       "          [1., 1., 1.]]]], requires_grad=True)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_dilation.weight = nn.Parameter(kernel)  # 自定义卷积核参数\n",
    "conv_dilation.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:37:32.032828Z",
     "start_time": "2020-05-19T12:37:32.028811Z"
    }
   },
   "outputs": [],
   "source": [
    "conv_dilation.bias = nn.Parameter(torch.zeros((1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:37:32.723328Z",
     "start_time": "2020-05-19T12:37:32.719310Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), dilation=(2, 2))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:42:07.256515Z",
     "start_time": "2020-05-19T12:42:06.907068Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[17.]]]], grad_fn=<SlowConvDilated2DBackward>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = conv_dilation(x)\n",
    "y # 3+1+1+2+1+1+2+3+3=17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 转置卷积\n",
    "\n",
    "![](./timg.gif)\n",
    "\n",
    "**转置卷积的理解**\n",
    "\n",
    "- 反卷积的实现原理实际就是卷积，但为了输出变大，就在输入图片中添加了padding\n",
    "\n",
    "\n",
    "- 输出大小计算公式：\n",
    "\n",
    "    $$y.shape=(x.shape-1)*stride-2*p+k$$\n",
    "\n",
    "- 对于$stride$大于1的也一样，不过还要在像素之间添加$padding$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:52:55.115586Z",
     "start_time": "2020-05-19T12:52:55.109618Z"
    }
   },
   "outputs": [],
   "source": [
    "upsample = nn.ConvTranspose2d(in_channels=1,\n",
    "                              out_channels=1,\n",
    "                              kernel_size=3, # 该参数设计为大小加2\n",
    "                              stride=1,\n",
    "                              padding=0)\n",
    "upsample.weight = nn.Parameter(torch.ones(1, 1, 3, 3))\n",
    "upsample.bias = nn.Parameter(torch.zeros((1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:54:37.428025Z",
     "start_time": "2020-05-19T12:54:37.422047Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1.],\n",
       "          [1., 1.]]]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_ = torch.ones((1, 1, 2, 2))\n",
    "in_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:54:37.819378Z",
     "start_time": "2020-05-19T12:54:37.815200Z"
    }
   },
   "outputs": [],
   "source": [
    "out_ = upsample(in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:54:38.268717Z",
     "start_time": "2020-05-19T12:54:38.263721Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 4, 4])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:54:47.376328Z",
     "start_time": "2020-05-19T12:54:47.368360Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 2., 2., 1.],\n",
       "          [2., 4., 4., 2.],\n",
       "          [2., 4., 4., 2.],\n",
       "          [1., 2., 2., 1.]]]], grad_fn=<SlowConvTranspose2DBackward>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:57:08.398821Z",
     "start_time": "2020-05-19T12:57:08.392835Z"
    }
   },
   "outputs": [],
   "source": [
    "upsample = nn.ConvTranspose2d(\n",
    "    in_channels=1,\n",
    "    out_channels=1,\n",
    "    kernel_size=3,  # 该参数设计为大小加2\n",
    "    stride=2,\n",
    "    padding=0)\n",
    "upsample.weight = nn.Parameter(torch.ones(1, 1, 3, 3))\n",
    "upsample.bias = nn.Parameter(torch.zeros((1)))\n",
    "in_ = torch.ones((1, 1, 2, 2))\n",
    "out_ = upsample(in_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:57:16.046739Z",
     "start_time": "2020-05-19T12:57:16.041751Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 5, 5])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:57:24.286628Z",
     "start_time": "2020-05-19T12:57:24.279640Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1., 2., 1., 1.],\n",
       "          [1., 1., 2., 1., 1.],\n",
       "          [2., 2., 4., 2., 2.],\n",
       "          [1., 1., 2., 1., 1.],\n",
       "          [1., 1., 2., 1., 1.]]]], grad_fn=<SlowConvTranspose2DBackward>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 深度可分离卷积"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**关于组卷积**\n",
    "\n",
    "![](./dsc.jpg)\n",
    "\n",
    "**解析**\n",
    "\n",
    "- 输入通道数与卷积核通道数相同，与输出通道数相同\n",
    "\n",
    "- 每个通道进行卷积以后，不再进行通道相加融合\n",
    "\n",
    "- pytorch中通过$groups$参数设计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
    "\n",
    " - stride: controls the stride for the cross-correlation, a single number or a tuple.\n",
    " \n",
    " - padding: controls the amount of implicit zero-paddings on both sides for padding number of points for each dimension.\n",
    " \n",
    " - dilation: controls the spacing between the kernel points; also known as the à trous algorithm. It is harder to describe, but this link has a nice visualization of what dilation does.\n",
    " \n",
    " - groups: controls the connections between inputs and outputs. in_channels and out_channels must both be divisible by groups. For example,\n",
    " \n",
    "    - At groups=1, all inputs are convolved to all outputs.\n",
    "\t- At groups=2, the operation becomes equivalent to having two conv layers side by side, each seeing half the input channels, and producing half the output channels, and both subsequently concatenated.\n",
    "\t- At groups= in_channels, each input channel is convolved with its own set of filters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:33:59.295350Z",
     "start_time": "2020-05-19T12:33:59.290334Z"
    }
   },
   "outputs": [],
   "source": [
    "# 普通卷积\n",
    "common_conv = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=5, groups=1)\n",
    "common_conv.weight = nn.Parameter(torch.ones((1, 3, 5, 5)))\n",
    "common_conv.bias = nn.Parameter(torch.zeros([1]))\n",
    "x = torch.ones((1, 3, 12, 12))\n",
    "y = common_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:34:04.561054Z",
     "start_time": "2020-05-19T12:34:04.545088Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]],\n",
       "\n",
       "         [[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "          [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:34:08.768015Z",
     "start_time": "2020-05-19T12:34:08.764031Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 8])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:34:09.318425Z",
     "start_time": "2020-05-19T12:34:09.310417Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[75., 75., 75., 75., 75., 75., 75., 75.],\n",
       "          [75., 75., 75., 75., 75., 75., 75., 75.],\n",
       "          [75., 75., 75., 75., 75., 75., 75., 75.],\n",
       "          [75., 75., 75., 75., 75., 75., 75., 75.],\n",
       "          [75., 75., 75., 75., 75., 75., 75., 75.],\n",
       "          [75., 75., 75., 75., 75., 75., 75., 75.],\n",
       "          [75., 75., 75., 75., 75., 75., 75., 75.],\n",
       "          [75., 75., 75., 75., 75., 75., 75., 75.]]]],\n",
       "       grad_fn=<ThnnConv2DBackward>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y # 每个元素应该是 25+25+25=75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:34:39.149079Z",
     "start_time": "2020-05-19T12:34:39.142105Z"
    }
   },
   "outputs": [],
   "source": [
    "# 组卷积 groups = in_channels\n",
    "depth_conv = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=5, groups=3)\n",
    "depth_conv.weight = nn.Parameter(torch.ones((3, 1, 5, 5)))\n",
    "depth_conv.bias=nn.Parameter(torch.zeros((3)))\n",
    "y_ = depth_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:34:40.828836Z",
     "start_time": "2020-05-19T12:34:40.824820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 8, 8])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:34:41.493066Z",
     "start_time": "2020-05-19T12:34:41.478073Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[25., 25., 25., 25., 25., 25., 25., 25.],\n",
       "          [25., 25., 25., 25., 25., 25., 25., 25.],\n",
       "          [25., 25., 25., 25., 25., 25., 25., 25.],\n",
       "          [25., 25., 25., 25., 25., 25., 25., 25.],\n",
       "          [25., 25., 25., 25., 25., 25., 25., 25.],\n",
       "          [25., 25., 25., 25., 25., 25., 25., 25.],\n",
       "          [25., 25., 25., 25., 25., 25., 25., 25.],\n",
       "          [25., 25., 25., 25., 25., 25., 25., 25.]],\n",
       "\n",
       "         [[25., 25., 25., 25., 25., 25., 25., 25.],\n",
       "          [25., 25., 25., 25., 25., 25., 25., 25.],\n",
       "          [25., 25., 25., 25., 25., 25., 25., 25.],\n",
       "          [25., 25., 25., 25., 25., 25., 25., 25.],\n",
       "          [25., 25., 25., 25., 25., 25., 25., 25.],\n",
       "          [25., 25., 25., 25., 25., 25., 25., 25.],\n",
       "          [25., 25., 25., 25., 25., 25., 25., 25.],\n",
       "          [25., 25., 25., 25., 25., 25., 25., 25.]],\n",
       "\n",
       "         [[25., 25., 25., 25., 25., 25., 25., 25.],\n",
       "          [25., 25., 25., 25., 25., 25., 25., 25.],\n",
       "          [25., 25., 25., 25., 25., 25., 25., 25.],\n",
       "          [25., 25., 25., 25., 25., 25., 25., 25.],\n",
       "          [25., 25., 25., 25., 25., 25., 25., 25.],\n",
       "          [25., 25., 25., 25., 25., 25., 25., 25.],\n",
       "          [25., 25., 25., 25., 25., 25., 25., 25.],\n",
       "          [25., 25., 25., 25., 25., 25., 25., 25.]]]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_ # 没有特征融合 只有25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:35:14.825623Z",
     "start_time": "2020-05-19T12:35:14.819640Z"
    }
   },
   "outputs": [],
   "source": [
    "# 深度可分离卷积包含了 1x1卷积负责通道融合\n",
    "merge_conv = nn.Conv2d(in_channels=3, out_channels=1, kernel_size=1)\n",
    "merge_conv.weight = nn.Parameter(torch.ones((1, 3, 1, 1)))\n",
    "merge_conv.bias = nn.Parameter(torch.zeros((1)))\n",
    "out = merge_conv(y_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:35:15.282051Z",
     "start_time": "2020-05-19T12:35:15.278069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 8, 8])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-19T12:35:15.780511Z",
     "start_time": "2020-05-19T12:35:15.771502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[75., 75., 75., 75., 75., 75., 75., 75.],\n",
       "          [75., 75., 75., 75., 75., 75., 75., 75.],\n",
       "          [75., 75., 75., 75., 75., 75., 75., 75.],\n",
       "          [75., 75., 75., 75., 75., 75., 75., 75.],\n",
       "          [75., 75., 75., 75., 75., 75., 75., 75.],\n",
       "          [75., 75., 75., 75., 75., 75., 75., 75.],\n",
       "          [75., 75., 75., 75., 75., 75., 75., 75.],\n",
       "          [75., 75., 75., 75., 75., 75., 75., 75.]]]],\n",
       "       grad_fn=<ThnnConv2DBackward>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
