{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNeSt网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**提出背景**\n",
    "\n",
    "- ResNet等一些基础卷积神经网络是针对于图像分类而设计的。由于有限的感受野大小以及缺乏跨通道之间的相互作用，这些网络可能不适合于其它的一些领域像目标检测、图像分割等。这意味着要提高给定计算机视觉任务的性能，需要“网络手术”来修改ResNet，以使其对特定任务更加有效。\n",
    "\n",
    "\n",
    "- 实践证明ResNeSt网络确实有更高的泛化能力"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**创新点与借鉴**\n",
    "\n",
    "- GoogleNet 采用了Multi-path机制，其中每个网络块均由不同的卷积kernels组成。\n",
    "\n",
    "- ResNeXt在ResNet bottle模块中采用组卷积，将multi-path结构转换为统一操作。\n",
    "\n",
    "- SE-Net 通过自适应地重新校准通道特征响应来引入通道注意力（channel-attention）机制。\n",
    "\n",
    "- SK-Net 通过两个网络分支引入特征图空间注意力（feature-map attention）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-21T13:08:59.385858Z",
     "start_time": "2020-05-21T13:08:59.379874Z"
    }
   },
   "source": [
    "**Split Attention BLOCK**\n",
    "\n",
    "![](./Split.jpg)\n",
    "\n",
    "**注释**\n",
    "\n",
    "- Step$1$\n",
    "    \n",
    "      将该cardinality group的输入分成r个split，每个split经过一些变换后，进入到split-attention中，先用element-wise sum的方式将特征图融合到一起（输出维度：H×W×C）\n",
    "\n",
    "- Step$2$\n",
    "\n",
    "      将融合后的feature map指向global average pooling，即将图像空间维度压缩（输出维度：C ）\n",
    "      \n",
    "- Step$3$\n",
    "\n",
    "      step3，结合softmax计算出每个split的权重,图中的dense c实现方式是用两个全连接层\n",
    "\n",
    "- step$4$\n",
    "        \n",
    "      将每个split-attention模块输入的每个split的feature map和计算出来的每个split的权重相乘，得到一个cardinality group的weighted fusion（输出维度：H×W×C）\n",
    "      \n",
    "      \n",
    "**实质**\n",
    "\n",
    "    可见，split-attention其实就是给每一组split的feature map计算其对应的权重，然后再融合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ResNeSt BLOCK**\n",
    "\n",
    "![](./resnest.png)\n",
    "\n",
    "**注释**\n",
    "\n",
    "- 首先是借鉴了ResNeXt网络的思想，将输入分为K个，每一个记为Cardinal1-k ，然后又将每个Cardinal拆分成R个，每一个记为Split1-r，所以总共有G=KR个组。\n",
    "\n",
    "\n",
    "- step$1$\n",
    "\n",
    "    将输入的所有feature map分成不同的cardinality group\n",
    "    \n",
    "- step$2$\n",
    "\n",
    "    每个cardinality group再分成不同的split\n",
    "\n",
    "- step$3$\n",
    "    \n",
    "    再用split-attention计算每个split的权重，再融合后作为每个cardinality group的输出\n",
    "\n",
    "- step$4$\n",
    "\n",
    "    将所有的cardinality group的feature map在channel维度concate到一起\n",
    "\n",
    "- step$5$\n",
    "\n",
    "    再执行一次conv（改变channel个数）用skip connection将ResNeSt Block的原始输入特征融合进来（融合方式为element-wise sum）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
